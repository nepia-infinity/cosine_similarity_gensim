# 社内問い合わせ 類似検索システム

このプロジェクトは、過去の社内問い合わせデータと新しい問い合わせ内容を比較し、意味的に類似するものを検索・提示するシステムです。

OpenAIの`text-embedding-3-small`モデルを利用して、高精度なセマンティック検索を実現します。

こちらの[Twwet](https://x.com/rk611/status/1983791317827383301)を触発され簡単なテストコードを作成しました。

## GASでやっている処理

>新たな問い合わせの文章をOpenAI APIに送信する。
>
> - まず、いい感じに1文に要約する
> - 次に、その要約文のベクトル（embedding）を取得する
>
> 過去の全問合せのそれぞれの要約とそのベクトルはあらかじめ取得してあり、シートに記録してあるので、それぞれとのコサイン類似度を計算する。
> 
> さらに、新たな問い合わせの文章と過去の文章のキーワード一致率を、簡易的な2-gramで比較する。
> 
> コサイン類似度 * 0.8 ＋ キーワード一致率 * 0.2 の値が大きい順に並べ、類似率が0.5以上の事例を最大5件、Slackに投稿する。

---

# 🧠 使用技術の解説

## ✅ コサイン類似度とは？

- 「今日の天気は晴れです」
- 「外はとてもいい天気ですね」

この2つの文は使っている単語は違いますが、意味は似ています。コンピュータは、このような文章や単語を「ベクトル」と呼ばれる数値の並びとして扱います。

コサイン類似度は、これら2つのベクトルが**どのくらい同じ方向を向いているか**を測る指標です。

ベクトルの向きが似ていればいるほど「意味が近い」と判断し、完全に同じ向きなら `1`、全く関係ない向きなら `0` に近い値を取ります。

この仕組みを使うことで、表面的な単語の一致だけでなく、文脈的な意味の近さで類似性を判断できます。

この技術を応用すれば、新しい問い合わせに対して過去の類似した回答を自動で提示するなど、社内問い合わせ対応の効率化・自動化が期待できます。

## 📝 形態素解析とは？

日本語の文章を、意味を持つ最小単位の「形態素（単語）」に分割し、それぞれの品詞などを判別する処理のことです。

(例)東京都に住んでいます

- `東京` (名詞), `都` (名詞), `に` (助詞), `住ん` (動詞), `で` (助詞), `い` (動詞), `ます` (助動詞)

**Gensimのような従来の自然言語処理ライブラリでは、この形態素解析が必須の前処理でした。**

しかし、**OpenAI Embedding APIのような最新の言語モデルでは、より高度な仕組みで文章を直接理解できるため、この前処理は不要です。** これにより、開発プロセスが大幅に簡略化されています。

## 🔎 セマンティック検索とは？

従来のキーワード検索が、入力された単語（キーワード）に完全に一致するものを探すのに対し、セマンティック検索は**単語や文章の「意味」を理解して**、関連性の高い結果を探し出す検索手法です。

例えば、「PCが動かない」と検索した場合でも、「パソコンの電源が入らない」「ノートPCがフリーズした」といった、**表現は違うが意図は同じ**である問い合わせを見つけ出すことができます。

このプロジェクトでは、OpenAIのEmbedding技術を使ってこのセマンティック検索を実現しています。

## 代表的なライブラリとそれぞれの役割

機械学習プロジェクトでは、役割の異なる複数のライブラリを組み合わせて利用するのが一般的です。

### 🧩 Scikit-learn: 汎用的な機械学習フレームワーク
- Pythonの代表的な機械学習ライブラリで、分類・回帰・クラスタリングなど、多種多様なアルゴリズムを統一されたインターフェースで提供します。
- **役割:** 数値化された特徴量を入力として受け取り、**予測モデルを構築・学習・評価する**ための汎用的な基盤です。

### 💬 Gensim: 自然言語処理（NLP）特化のベクトル化ライブラリ
- Word2Vec, Doc2Vecなど、テキストデータを意味的な**数値ベクトルに変換する**ことに特化した専門ライブラリです。
- **役割:** Scikit-learnなどの機械学習モデルがテキストを扱えるようにするための、高度な**前処理（特徴量エンジニアリング）**を担います。

### ⚡ LightGBM: 高速な勾配ブースティングライブラリ
- Microsoftが開発した、決定木ベースの勾配ブースティングの高性能な実装です。
- **役割:** 大規模なデータセットに対しても高速に学習でき、高い予測精度が求められるテーブルデータ（CSV形式など）のタスクで広く採用されています。

## アプローチの選択：OpenAI API vs ローカルモデル (Gensim)

テキストのベクトル化において、どちらの技術を選ぶべきかはプロジェクトの要件によりますが、以下の考え方が有効です。

> 「まずはOpenAIを試す」というのが、現在の最も効率的で効果的なアプローチと言えるでしょう。
>
> それで精度や要件を満たせるのであれば、そのまま利用するのが最善です。
>
> コストやセキュリティといった特別な制約に直面した場合に、初めてGensimのようなローカルモデルの導入を検討するという流れが合理的です。

---

# 🚀 実行方法

### 1. 前提条件

- Python 3.11 環境
- `.env` ファイルをプロジェクトルートに作成し、OpenAIのAPIキーを記述します。
  ```
  OPENAI_API_KEY="sk-..."
  ```
- 必要なライブラリをインストールします。
  ```bash
  pip install -r requirements.txt
  pip install openai pandas python-dotenv
  ```
  (`requirements.txt` に `openai`, `pandas`, `python-dotenv` がなければ追記してください)

### 2. Step 1: 問い合わせデータのEmbedding化 (`create_embeddings.py`)

まず、`csv/in_house_inquiries.csv` に含まれる全ての問い合わせテキスト��、OpenAI APIを使ってベクトル（Embedding）に変換し、結果を `csv/in_house_inquiries_with_embeddings.csv` に保存します。

**この処理は、`in_house_inquiries.csv` の内容を更新した際に一度だけ実行すればOKです。**

```bash
python create_embeddings.py
```

### 3. Step 2: 類似問い合わせの検索 (`find_similar_inquiries.py`)

次に、新しい問い合わせ内容と、Step 1で作成したEmbeddingデータとのコサイン類似度を計算し、最も似ている問い合わせを3つ見つけ出します。

スクリプト内の `input_text` 変数を検索したい内容に書き換えてから実行してください。

```python
# find_similar_inquiries.py

# --- ここに問い合わせ内容を入力してください ---
input_text = "パソコンが起動しない"
# -----------------------------------------
```

```bash
python find_similar_inquiries.py
```

#### 実行結果の例

入力されたテキスト: `パソコンが起動しない`

| 類似度 | 問い合わせ内容 |
| :--- | :--- |
| 0.6493 | PCの電源が入りません。 |
| 0.5781 | PCの画面が突然真っ暗になりました。 |
| 0.5119 | ノートパソコンの動作が非常に遅いです。改善策はありますか？ |

---

# Appendix: 過去のアプローチ (Doc2Vec/GiNZA)

当初、オープンソースのGensimライブラリ（Doc2Vec）と日本語形態素解析器GiNZAを用いて、ローカル環境でモデルを学習・推論するアプローチを検討しました。（`test_gensim.py`）

### 課題
- 約100件という少ない学習データでは、単語間の関係性を十分に学習できず、人間が見て関連性の低い文章を「類似度が高い」と判断してしまうケースが多く見られました。
- 例えば、「Pythonが好き」というクエリに対し、「営業目標を達成する」といった無関係な文章が高い類似度で返されるなど、精度に課題がありました。

この結果から、少量のデータでも高い精度を発揮できる、事前学習済みのOpenAI Embeddingモデルを採用するアプローチに切り替えました。
